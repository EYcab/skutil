{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from skutil.feature_selection import MulticollinearityFilterer\n",
    "\n",
    "# import skutil\n",
    "import skutil\n",
    "skutil.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame.from_records(data=iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, iris.target, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RF accuracy: 1.00000\n",
      "Test RF accuracy: 0.78947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from skutil.preprocessing import BoxCoxTransformer, SelectiveScaler\n",
    "from skutil.decomposition import SelectivePCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# build a pipeline\n",
    "pipe = Pipeline([\n",
    "        ('collinearity', MulticollinearityFilterer(threshold=0.85)),\n",
    "        ('scaler'      , SelectiveScaler()),\n",
    "        ('boxcox'      , BoxCoxTransformer()),\n",
    "        ('pca'         , SelectivePCA(n_components=0.9)),\n",
    "        ('model'       , RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# fit the pipe, report scores\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# report scores\n",
    "print 'Train RF accuracy: %.5f' % accuracy_score(y_train, pipe.predict(X_train))\n",
    "print 'Test RF accuracy: %.5f'  % accuracy_score(y_test,  pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance isn't bad. The training accuracy is phenomenal, but the validation accuracy is sub-par. Plus, there's quite of variance in the model, isn't there? Let's try to improve our performance as well as reduce the variability (while sacrificing some bias, unfortunately).\n",
    "\n",
    "### Can we make this better with a gridsearch?\n",
    "\n",
    "*Beware, this grid can be a lot to handle for an older or weaker machine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RF accuracy: 0.96429\n",
      "Test RF accuracy: 0.89474\n"
     ]
    }
   ],
   "source": [
    "from skutil.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from skutil.feature_selection import NearZeroVarianceFilterer\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# default CV does not shuffle, so we define our own\n",
    "custom_cv = KFold(n=y_train.shape[0], n_folds=5, shuffle=True, random_state=42)\n",
    "\n",
    "# build a pipeline -- let's also add a NearZeroVarianceFilterer prior to PCA\n",
    "pipe = Pipeline([\n",
    "        ('collinearity', MulticollinearityFilterer(threshold=0.85)),\n",
    "        ('scaler'      , SelectiveScaler()),\n",
    "        ('boxcox'      , BoxCoxTransformer()),\n",
    "        ('filterer'    , NearZeroVarianceFilterer()),\n",
    "        ('pca'         , SelectivePCA(n_components=0.9)),\n",
    "        ('model'       , RandomForestClassifier(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# let's define a set of hyper-parameters over which to search\n",
    "hp = {\n",
    "    'collinearity__threshold' : uniform(loc=.8, scale=.15),\n",
    "    'collinearity__method'    : ['pearson','kendall','spearman'],\n",
    "    'scaler__scaler'          : [StandardScaler(), RobustScaler()],\n",
    "    'filterer__threshold'     : uniform(loc=1e-6, scale=0.005),\n",
    "    'pca__n_components'       : uniform(loc=.75, scale=.2),\n",
    "    'pca__whiten'             : [True, False],\n",
    "    'model__n_estimators'     : randint(5,100),\n",
    "    'model__max_depth'        : randint(2,25),\n",
    "    'model__min_samples_leaf' : randint(1,15),\n",
    "    'model__max_features'     : uniform(loc=.5, scale=.5),\n",
    "    'model__max_leaf_nodes'   : randint(10,75)\n",
    "}\n",
    "\n",
    "# define the gridsearch\n",
    "search = RandomizedSearchCV(pipe, hp,\n",
    "                            n_iter=50,\n",
    "                            scoring='accuracy',\n",
    "                            cv=custom_cv,\n",
    "                            random_state=42)\n",
    "\n",
    "# fit the search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# report scores\n",
    "print 'Train RF accuracy: %.5f' % accuracy_score(y_train, search.predict(X_train))\n",
    "print 'Test RF accuracy: %.5f' % accuracy_score(y_test, search.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better! We've dramatically reduced the variance in our model, but we've taken a slight hit in terms of bias. With different models, or even creating an ensemble of different models (ensemble of ensembles?), we could probably create an even better score.\n",
    "\n",
    "It's also important to note that we were relatively cavalier in our preprocessing... in a real world situation, you'd check each step and ensure how we're transforming our data makes sense. \n",
    "\n",
    "Finally, note that the `skutil` grid search API differs slightly from the `sklearn` one... in `sklearn`, we can call `search.best_estimator_.predict`, however when using `SelectiveMixin` transformers, names may be internally altered by the grid search API for support with `sklearn` cross_validation. Thus, in `skutil`, use `search.predict` instead.\n",
    "\n",
    "Here are the best parameters for the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collinearity__method': 'kendall',\n",
       " 'collinearity__threshold': 0.8460347290105728,\n",
       " 'filterer__threshold': 0.0029398333218510707,\n",
       " 'model__max_depth': 17,\n",
       " 'model__max_features': 0.5041972101764756,\n",
       " 'model__max_leaf_nodes': 52,\n",
       " 'model__min_samples_leaf': 3,\n",
       " 'model__n_estimators': 31,\n",
       " 'pca__n_components': 0.8856086249821638,\n",
       " 'pca__whiten': True,\n",
       " 'scaler__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model persistence\n",
    "\n",
    "Once you get to a point where you're happy with your model, write it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# write the model\n",
    "joblib.dump(search, 'final_model.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from a persistent model\n",
    "\n",
    "When new data needs to be predicted on (for the sake of example here, we'll use iris, but you wouldn't really apply the same model to in-sample data), read your model back and make the predictions using `.predict(new_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n",
      "0.946666666667\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "# load the model\n",
    "final_model = joblib.load('final_model.pkl')\n",
    "\n",
    "# load your data\n",
    "# new_data = pd.read_csv('...')\n",
    "# ... any other pre-processing you may have done outside of the pipeline\n",
    "\n",
    "# here's our example data\n",
    "new_data = X\n",
    "\n",
    "# make predictions\n",
    "predictions = final_model.predict(new_data)\n",
    "\n",
    "# view the top few\n",
    "print(predictions[:5])\n",
    "\n",
    "# view the performance (we can do this because we have the ground truth)\n",
    "print(accuracy_score(iris.target, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# disk cleanup for git\n",
    "!rm final_model.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
