{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from skutil.preprocessing import BoxCoxTransformer\n",
    "from skutil.feature_selection import MulticollinearityFilterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame.from_records(data=iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, iris.target, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a simple Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RF accuracy: 1.00000\n",
      "Test RF accuracy: 0.82222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from skutil.preprocessing import SelectiveScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# build a pipeline\n",
    "pipe = Pipeline([\n",
    "        ('collinearity', MulticollinearityFilterer(threshold=0.85)),\n",
    "        ('scaler'      , SelectiveScaler()),\n",
    "        ('boxcox'      , BoxCoxTransformer()),\n",
    "        ('pca'         , PCA(n_components=0.9)),\n",
    "        ('model'       , RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# fit the pipe, report scores\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# report scores\n",
    "print 'Train RF accuracy: %.5f' % accuracy_score(y_train, pipe.predict(X_train))\n",
    "print 'Test RF accuracy: %.5f'  % accuracy_score(y_test,  pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we make this better with a gridsearch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RF accuracy: 0.97143\n",
      "Test RF accuracy: 0.91111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# default CV does not shuffle, so we define our own\n",
    "custom_cv = KFold(n=y_train.shape[0], n_folds=5, shuffle=True, random_state=42)\n",
    "\n",
    "# build a pipeline\n",
    "pipe = Pipeline([\n",
    "        ('collinearity', MulticollinearityFilterer(threshold=0.85)),\n",
    "        ('scaler'      , SelectiveScaler()),\n",
    "        ('boxcox'      , BoxCoxTransformer()),\n",
    "        ('pca'         , PCA(n_components=0.9)),\n",
    "        ('model'       , RandomForestClassifier(n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "# let's define a set of hyper-parameters over which to search\n",
    "hp = {\n",
    "    'collinearity__threshold' : uniform(loc=.8, scale=.15),\n",
    "    'collinearity__method'    : ['pearson','kendall','spearman'],\n",
    "    'scaler__scaler'          : [StandardScaler(), RobustScaler()],\n",
    "    'pca__n_components'       : uniform(loc=.75, scale=.2),\n",
    "    'pca__whiten'             : [True, False],\n",
    "    'model__n_estimators'     : randint(5,100),\n",
    "    'model__max_depth'        : randint(2,25),\n",
    "    'model__min_samples_leaf' : randint(1,15),\n",
    "    'model__max_features'     : uniform(loc=.5, scale=.5),\n",
    "    'model__max_leaf_nodes'   : randint(10,75)\n",
    "}\n",
    "\n",
    "# define the gridsearch\n",
    "search = RandomizedSearchCV(pipe, hp,\n",
    "                            n_iter=50,\n",
    "                            scoring='accuracy',\n",
    "                            cv=custom_cv,\n",
    "                            random_state=42)\n",
    "\n",
    "# fit the search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# get the best estimator:\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# report scores\n",
    "print 'Train RF accuracy: %.5f' % accuracy_score(y_train, best_model.predict(X_train))\n",
    "print 'Test RF accuracy: %.5f' % accuracy_score(y_test, best_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better! We've dramatically reduced the variance in our model, but we've taken a slight hit in terms of bias. With different models, or even creating an ensemble of different models (ensemble of ensembles?), we could probably create an even better score.\n",
    "\n",
    "It's also important to note that we were relatively cavalier in our preprocessing... in a real world situation, you'd check each step and ensure how we're transforming our data makes sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model persistence\n",
    "\n",
    "Once you get to a point where you're happy with your model, write it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# write the model\n",
    "joblib.dump(best_model, 'final_model.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from a persistent model\n",
    "\n",
    "When new data needs to be predicted on (for the sake of example here, we'll use iris, but you wouldn't really apply the same model to in-sample data), read your model back and make the predictions using `.predict(new_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "final_model = joblib.load('final_model.pkl')\n",
    "\n",
    "# load your data\n",
    "# new_data = pd.read_csv('...')\n",
    "# ... any other pre-processing you may have done outside of the pipeline\n",
    "\n",
    "# here's our example data\n",
    "new_data = X\n",
    "\n",
    "# make predictions\n",
    "predictions = final_model.predict(new_data)\n",
    "\n",
    "# view the top few\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# disk cleanup for git\n",
    "!rm final_model.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
