

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>skutil.grid_search &mdash; skutil 0.1.5 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="search" title="Search" href="../../search.html"/>
    <link rel="top" title="skutil 0.1.5 documentation" href="../../index.html"/>
        <link rel="up" title="Module code" href="../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> skutil
          

          
            
            <img src="../../_static/h2o-sklearn.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.1.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../rsts/setup/index.html">Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rsts/codebase/index.html">Codebase</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rsts/examples/index.html">Examples</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">skutil</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          





<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
          <li><a href="../index.html">Module code</a> &raquo;</li>
      
    <li>skutil.grid_search</li>
      <li class="wy-breadcrumbs-aside">
        
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for skutil.grid_search</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span><span class="p">,</span> <span class="n">absolute_import</span><span class="p">,</span> <span class="n">print_function</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">.base</span> <span class="k">import</span> <span class="n">overrides</span>
<span class="kn">from</span> <span class="nn">.utils.fixes</span> <span class="k">import</span> <span class="p">(</span><span class="n">_validate_X</span><span class="p">,</span> <span class="n">_validate_y</span><span class="p">,</span>
                          <span class="n">_check_param_grid</span><span class="p">,</span> <span class="n">_as_numpy</span><span class="p">,</span> <span class="n">_CVScoreTuple</span><span class="p">)</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;GridSearchCV&#39;</span><span class="p">,</span>
    <span class="s1">&#39;RandomizedSearchCV&#39;</span>
<span class="p">]</span>

<span class="c1"># deprecation in sklearn 0.18</span>
<span class="k">if</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;=</span> <span class="s1">&#39;0.18&#39;</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">sklearn.model_selection</span> <span class="k">as</span> <span class="nn">ms</span>


    <span class="k">class</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Exhaustive search over specified parameter values for an estimator.</span>
<span class="sd">        This class is a skutil fix of the sklearn 0.18 GridSearchCV module, and allows</span>
<span class="sd">        use with SelectiveMixins and other skutil classes that don&#39;t interact so kindly</span>
<span class="sd">        with other sklearn 0.18 structures (i.e. when ``as_df`` is True in many transformers,</span>
<span class="sd">        predicting on a column vector from a pd.DataFrame will cause issues in sklearn).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        estimator : estimator object.</span>
<span class="sd">            This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">            Either estimator needs to provide a ``score`` function,</span>
<span class="sd">            or ``scoring`` must be passed.</span>

<span class="sd">        param_grid : dict or list of dictionaries</span>
<span class="sd">            Dictionary with parameters names (string) as keys and lists of</span>
<span class="sd">            parameter settings to try as values, or a list of such</span>
<span class="sd">            dictionaries, in which case the grids spanned by each dictionary</span>
<span class="sd">            in the list are explored. This enables searching over any sequence</span>
<span class="sd">            of parameter settings.</span>

<span class="sd">        scoring : string, callable or None, default=None</span>
<span class="sd">            A string (see model evaluation documentation) or</span>
<span class="sd">            a scorer callable object / function with signature</span>
<span class="sd">            ``scorer(estimator, X, y)``.</span>
<span class="sd">            If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">        fit_params : dict, optional</span>
<span class="sd">            Parameters to pass to the fit method.</span>

<span class="sd">        n_jobs : int, default=1</span>
<span class="sd">            Number of jobs to run in parallel.</span>

<span class="sd">        pre_dispatch : int, or string, optional</span>
<span class="sd">            Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">            execution. Reducing this number can be useful to avoid an</span>
<span class="sd">            explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">            than CPUs can process. This parameter can be:</span>
<span class="sd">                - None, in which case all the jobs are immediately</span>
<span class="sd">                  created and spawned. Use this for lightweight and</span>
<span class="sd">                  fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">                  spawning of the jobs</span>
<span class="sd">                - An int, giving the exact number of total jobs that are</span>
<span class="sd">                  spawned</span>
<span class="sd">                - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">                  as in &#39;2*n_jobs&#39;</span>

<span class="sd">        iid : boolean, default=True</span>
<span class="sd">            If True, the data is assumed to be identically distributed across</span>
<span class="sd">            the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">            and not the mean loss across the folds.</span>

<span class="sd">        cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">            Determines the cross-validation splitting strategy.</span>
<span class="sd">            Possible inputs for cv are:</span>
<span class="sd">              - None, to use the default 3-fold cross validation,</span>
<span class="sd">              - integer, to specify the number of folds in a ``(Stratified)KFold``,</span>
<span class="sd">              - An object to be used as a cross-validation generator.</span>
<span class="sd">              - An iterable yielding train, test splits.</span>
<span class="sd">            For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">            either binary or multiclass, ``StratifiedKFold`` is used. In all</span>
<span class="sd">            other cases, ``KFold`` is used.</span>

<span class="sd">        refit : boolean, default=True</span>
<span class="sd">            Refit the best estimator with the entire dataset.</span>
<span class="sd">            If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">            this GridSearchCV instance after fitting.</span>

<span class="sd">        verbose : integer</span>
<span class="sd">            Controls the verbosity: the higher, the more messages.</span>

<span class="sd">        error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">            Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">            If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">            FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">            step, which will always raise the error.</span>

<span class="sd">        return_train_score : boolean, default=True</span>
<span class="sd">            If ``&#39;False&#39;``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">            scores.</span>

<span class="sd">        </span>
<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>

<span class="sd">        cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">            A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">            imported into a pandas ``DataFrame``.</span>

<span class="sd">            For instance, the following table</span>

<span class="sd">            +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">            |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_....|</span>
<span class="sd">            +============+===========+============+=================+===+=========+</span>
<span class="sd">            |  &#39;poly&#39;    |     --    |      2     |        0.8      |...|    2    |</span>
<span class="sd">            +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">            |  &#39;poly&#39;    |     --    |      3     |        0.7      |...|    4    |</span>
<span class="sd">            +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">            |  &#39;rbf&#39;     |     0.1   |     --     |        0.8      |...|    3    |</span>
<span class="sd">            +------------+-----------+------------+-----------------+---+---------+</span>
<span class="sd">            |  &#39;rbf&#39;     |     0.2   |     --     |        0.9      |...|    1    |</span>
<span class="sd">            +------------+-----------+------------+-----------------+---+---------+</span>

<span class="sd">            will be represented by a ``cv_results_`` dict of:</span>

<span class="sd">                {</span>
<span class="sd">                    &#39;param_kernel&#39;: masked_array(data = [&#39;poly&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                                 mask = [False False False False]...)</span>
<span class="sd">                    &#39;param_gamma&#39;: masked_array(data = [-- -- 0.1 0.2],</span>
<span class="sd">                                                mask = [ True  True False False]...),</span>
<span class="sd">                    &#39;param_degree&#39;: masked_array(data = [2.0 3.0 -- --],</span>
<span class="sd">                                                 mask = [False False  True  True]...),</span>
<span class="sd">                    &#39;split0_test_score&#39;  : [0.8, 0.7, 0.8, 0.9],</span>
<span class="sd">                    &#39;split1_test_score&#39;  : [0.82, 0.5, 0.7, 0.78],</span>
<span class="sd">                    &#39;mean_test_score&#39;    : [0.81, 0.60, 0.75, 0.82],</span>
<span class="sd">                    &#39;std_test_score&#39;     : [0.02, 0.01, 0.03, 0.03],</span>
<span class="sd">                    &#39;rank_test_score&#39;    : [2, 4, 3, 1],</span>
<span class="sd">                    &#39;split0_train_score&#39; : [0.8, 0.9, 0.7],</span>
<span class="sd">                    &#39;split1_train_score&#39; : [0.82, 0.5, 0.7],</span>
<span class="sd">                    &#39;mean_train_score&#39;   : [0.81, 0.7, 0.7],</span>
<span class="sd">                    &#39;std_train_score&#39;    : [0.03, 0.03, 0.04],</span>
<span class="sd">                    &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">                    &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">                    &#39;mean_score_time&#39;    : [0.007, 0.06, 0.04, 0.04],</span>
<span class="sd">                    &#39;std_score_time&#39;     : [0.001, 0.002, 0.003, 0.005],</span>
<span class="sd">                    &#39;params&#39;             : [{&#39;kernel&#39;: &#39;poly&#39;, &#39;degree&#39;: 2}, ...],</span>
<span class="sd">                }</span>

<span class="sd">            NOTE that the key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">            settings dict for all the parameter candidates. The ``mean_fit_time``, </span>
<span class="sd">            ``std_fit_time``, ``mean_score_time`` and ``std_score_time`` are all in seconds.</span>

<span class="sd">        best_estimator_ : estimator</span>
<span class="sd">            Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">            which gave highest score (or smallest loss if specified)</span>
<span class="sd">            on the left out data. Not available if refit=False.</span>

<span class="sd">        best_score_ : float</span>
<span class="sd">            Score of best_estimator on the left out data.</span>

<span class="sd">        best_params_ : dict</span>
<span class="sd">            Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">        best_index_ : int</span>
<span class="sd">            The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">            candidate parameter setting.</span>
<span class="sd">            The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">            the parameter setting for the best model, that gives the highest</span>
<span class="sd">            mean score (``search.best_score_``).</span>

<span class="sd">        scorer_ : function</span>
<span class="sd">            Scorer function used on the held out data to choose the best</span>
<span class="sd">            parameters for the model.</span>

<span class="sd">        n_splits_ : int</span>
<span class="sd">            The number of cross-validation splits (folds/iterations).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="nd">@overrides</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">)</span>
<div class="viewcode-block" id="GridSearchCV.fit"><a class="viewcode-back" href="../../rsts/codebase/skutil_model_selection.html#skutil.grid_search.GridSearchCV.fit">[docs]</a>        <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Run fit with all sets of parameters.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>

<span class="sd">            X : array-like, shape=(n_samples, n_features)</span>
<span class="sd">                Training vector, where n_samples is the number of samples and</span>
<span class="sd">                n_features is the number of features.</span>

<span class="sd">            y : array-like, shape=(n_samples,) or (n_samples, n_output), optional (default=None)</span>
<span class="sd">                Target relative to X for classification or regression;</span>
<span class="sd">                None for unsupervised learning.</span>

<span class="sd">            groups : array-like, shape=(n_samples,), optional (default=None)</span>
<span class="sd">                Group labels for the samples used while splitting the dataset into</span>
<span class="sd">                train/test set.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">GridSearchCV</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">_as_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">groups</span><span class="p">)</span></div>


    <span class="k">class</span> <span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">RandomizedSearchCV</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Randomized search on hyper parameters.</span>
<span class="sd">        This class is a skutil fix of the sklearn 0.18 RandomizedSearchCV module, and allows</span>
<span class="sd">        use with SelectiveMixins and other skutil classes that don&#39;t interact so kindly</span>
<span class="sd">        with other sklearn 0.18 structures (i.e. when ``as_df`` is True in many transformers,</span>
<span class="sd">        predicting on a column vector from a pd.DataFrame will cause issues in sklearn).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        estimator : estimator object.</span>
<span class="sd">            A object of that type is instantiated for each grid point.</span>
<span class="sd">            This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">            Either estimator needs to provide a ``score`` function,</span>
<span class="sd">            or ``scoring`` must be passed.</span>

<span class="sd">        param_distributions : dict</span>
<span class="sd">            Dictionary with parameters names (string) as keys and distributions</span>
<span class="sd">            or lists of parameters to try. Distributions must provide a ``rvs``</span>
<span class="sd">            method for sampling (such as those from scipy.stats.distributions).</span>
<span class="sd">            If a list is given, it is sampled uniformly.</span>

<span class="sd">        n_iter : int, default=10</span>
<span class="sd">            Number of parameter settings that are sampled. n_iter trades</span>
<span class="sd">            off runtime vs quality of the solution.</span>

<span class="sd">        scoring : string, callable or None, default=None</span>
<span class="sd">            A string (see model evaluation documentation) or</span>
<span class="sd">            a scorer callable object / function with signature</span>
<span class="sd">            ``scorer(estimator, X, y)``.</span>
<span class="sd">            If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">        fit_params : dict, optional</span>
<span class="sd">            Parameters to pass to the fit method.</span>

<span class="sd">        n_jobs : int, default=1</span>
<span class="sd">            Number of jobs to run in parallel.</span>

<span class="sd">        pre_dispatch : int, or string, optional</span>
<span class="sd">            Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">            execution. Reducing this number can be useful to avoid an</span>
<span class="sd">            explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">            than CPUs can process. This parameter can be:</span>
<span class="sd">                - None, in which case all the jobs are immediately</span>
<span class="sd">                  created and spawned. Use this for lightweight and</span>
<span class="sd">                  fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">                  spawning of the jobs</span>
<span class="sd">                - An int, giving the exact number of total jobs that are</span>
<span class="sd">                  spawned</span>
<span class="sd">                - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">                  as in &#39;2*n_jobs&#39;</span>

<span class="sd">        iid : boolean, default=True</span>
<span class="sd">            If True, the data is assumed to be identically distributed across</span>
<span class="sd">            the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">            and not the mean loss across the folds.</span>

<span class="sd">        cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">            Determines the cross-validation splitting strategy.</span>
<span class="sd">            Possible inputs for cv are:</span>
<span class="sd">              - None, to use the default 3-fold cross validation,</span>
<span class="sd">              - integer, to specify the number of folds in a ``(Stratified)KFold``,</span>
<span class="sd">              - An object to be used as a cross-validation generator.</span>
<span class="sd">              - An iterable yielding train, test splits.</span>
<span class="sd">            For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">            either binary or multiclass, ``StratifiedKFold`` is used. In all</span>
<span class="sd">            other cases, ``KFold`` is used.</span>

<span class="sd">        refit : boolean, default=True</span>
<span class="sd">            Refit the best estimator with the entire dataset.</span>
<span class="sd">            If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">            this RandomizedSearchCV instance after fitting.</span>

<span class="sd">        verbose : integer</span>
<span class="sd">            Controls the verbosity: the higher, the more messages.</span>

<span class="sd">        random_state : int or RandomState</span>
<span class="sd">            Pseudo random number generator state used for random uniform sampling</span>
<span class="sd">            from lists of possible values instead of scipy.stats distributions.</span>

<span class="sd">        error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">            Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">            If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">            FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">            step, which will always raise the error.</span>

<span class="sd">        return_train_score : boolean, default=True</span>
<span class="sd">            If ``&#39;False&#39;``, the ``cv_results_`` attribute will not include training</span>
<span class="sd">            scores.</span>


<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>

<span class="sd">        cv_results_ : dict of numpy (masked) ndarrays</span>
<span class="sd">            A dict with keys as column headers and values as columns, that can be</span>
<span class="sd">            imported into a pandas ``DataFrame``.</span>

<span class="sd">            For instance the following table:</span>

<span class="sd">            +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">            | param_kernel | param_gamma | split0_test_score |...|rank_test_score|</span>
<span class="sd">            +==============+=============+===================+===+===============+</span>
<span class="sd">            |    &#39;rbf&#39;     |     0.1     |        0.8        |...|       2       |</span>
<span class="sd">            +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">            |    &#39;rbf&#39;     |     0.2     |        0.9        |...|       1       |</span>
<span class="sd">            +--------------+-------------+-------------------+---+---------------+</span>
<span class="sd">            |    &#39;rbf&#39;     |     0.3     |        0.7        |...|       1       |</span>
<span class="sd">            +--------------+-------------+-------------------+---+---------------+</span>

<span class="sd">            will be represented by a ``cv_results_`` dict of:</span>

<span class="sd">                {</span>
<span class="sd">                    &#39;param_kernel&#39; : masked_array(data = [&#39;rbf&#39;, &#39;rbf&#39;, &#39;rbf&#39;],</span>
<span class="sd">                                                  mask = False),</span>
<span class="sd">                    &#39;param_gamma&#39;  : masked_array(data = [0.1 0.2 0.3], mask = False),</span>
<span class="sd">                    &#39;split0_test_score&#39;  : [0.8, 0.9, 0.7],</span>
<span class="sd">                    &#39;split1_test_score&#39;  : [0.82, 0.5, 0.7],</span>
<span class="sd">                    &#39;mean_test_score&#39;    : [0.81, 0.7, 0.7],</span>
<span class="sd">                    &#39;std_test_score&#39;     : [0.02, 0.2, 0.],</span>
<span class="sd">                    &#39;rank_test_score&#39;    : [3, 1, 1],</span>
<span class="sd">                    &#39;split0_train_score&#39; : [0.8, 0.9, 0.7],</span>
<span class="sd">                    &#39;split1_train_score&#39; : [0.82, 0.5, 0.7],</span>
<span class="sd">                    &#39;mean_train_score&#39;   : [0.81, 0.7, 0.7],</span>
<span class="sd">                    &#39;std_train_score&#39;    : [0.03, 0.03, 0.04],</span>
<span class="sd">                    &#39;mean_fit_time&#39;      : [0.73, 0.63, 0.43, 0.49],</span>
<span class="sd">                    &#39;std_fit_time&#39;       : [0.01, 0.02, 0.01, 0.01],</span>
<span class="sd">                    &#39;mean_score_time&#39;    : [0.007, 0.06, 0.04, 0.04],</span>
<span class="sd">                    &#39;std_score_time&#39;     : [0.001, 0.002, 0.003, 0.005],</span>
<span class="sd">                    &#39;params&#39; : [{&#39;kernel&#39; : &#39;rbf&#39;, &#39;gamma&#39; : 0.1}, ...],</span>
<span class="sd">                }</span>

<span class="sd">            NOTE that the key ``&#39;params&#39;`` is used to store a list of parameter</span>
<span class="sd">            settings dict for all the parameter candidates. The ``mean_fit_time``, </span>
<span class="sd">            ``std_fit_time``, ``mean_score_time`` and ``std_score_time`` are all in seconds.</span>

<span class="sd">        best_estimator_ : estimator</span>
<span class="sd">            Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">            which gave highest score (or smallest loss if specified)</span>
<span class="sd">            on the left out data. Not available if refit=False.</span>

<span class="sd">        best_score_ : float</span>
<span class="sd">            Score of best_estimator on the left out data.</span>

<span class="sd">        best_params_ : dict</span>
<span class="sd">            Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">        best_index_ : int</span>
<span class="sd">            The index (of the ``cv_results_`` arrays) which corresponds to the best</span>
<span class="sd">            candidate parameter setting.</span>
<span class="sd">            The dict at ``search.cv_results_[&#39;params&#39;][search.best_index_]`` gives</span>
<span class="sd">            the parameter setting for the best model, that gives the highest</span>
<span class="sd">            mean score (``search.best_score_``).</span>

<span class="sd">        scorer_ : function</span>
<span class="sd">            Scorer function used on the held out data to choose the best</span>
<span class="sd">            parameters for the model.</span>

<span class="sd">        n_splits_ : int</span>
<span class="sd">            The number of cross-validation splits (folds/iterations).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nd">@overrides</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">RandomizedSearchCV</span><span class="p">)</span>
<div class="viewcode-block" id="RandomizedSearchCV.fit"><a class="viewcode-back" href="../../rsts/codebase/skutil_model_selection.html#skutil.grid_search.RandomizedSearchCV.fit">[docs]</a>        <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Run fit on the estimator with randomly drawn parameters.</span>

<span class="sd">            Parameters</span>
<span class="sd">            ----------</span>

<span class="sd">            X : array-like, shape=(n_samples, n_features)</span>
<span class="sd">                Training vector, where n_samples is the number of samples and</span>
<span class="sd">                n_features is the number of features.</span>

<span class="sd">            y : array-like, shape=(n_samples,) or (n_samples, n_output), optional (default=None)</span>
<span class="sd">                Target relative to X for classification or regression;</span>
<span class="sd">                None for unsupervised learning.</span>

<span class="sd">            groups : array-like, shape=(n_samples,), optional (default=None)</span>
<span class="sd">                Group labels for the samples used while splitting the dataset into</span>
<span class="sd">                train/test set.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">RandomizedSearchCV</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">_as_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">groups</span><span class="p">)</span></div>
<span class="k">else</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    sklearn deprecates the GridSearch and cross validation API we know and</span>
<span class="sd">    love in 0.18, thus, we only define these methods if we&#39;re using &lt; 0.18.</span>
<span class="sd">    Otherwise, we&#39;ll use their default. These are defined in skutil.utils.fixes</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">.utils</span> <span class="k">import</span> <span class="n">fixes</span>


<div class="viewcode-block" id="GridSearchCV"><a class="viewcode-back" href="../../rsts/codebase/skutil_model_selection.html#skutil.grid_search.GridSearchCV">[docs]</a>    <span class="k">class</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">fixes</span><span class="o">.</span><span class="n">_SK17GridSearchCV</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Exhaustive search over specified parameter values for an estimator.</span>
<span class="sd">        This class is a skutil fix of the sklearn 0.17 GridSearchCV module, and allows</span>
<span class="sd">        use with SelectiveMixins and other skutil classes that don&#39;t interact so kindly</span>
<span class="sd">        with other sklearn 0.17 structures.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        estimator : estimator object.</span>
<span class="sd">            A object of that type is instantiated for each grid point.</span>
<span class="sd">            This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">            Either estimator needs to provide a ``score`` function,</span>
<span class="sd">            or ``scoring`` must be passed.</span>

<span class="sd">        param_grid : dict or list of dictionaries</span>
<span class="sd">            Dictionary with parameters names (string) as keys and lists of</span>
<span class="sd">            parameter settings to try as values, or a list of such</span>
<span class="sd">            dictionaries, in which case the grids spanned by each dictionary</span>
<span class="sd">            in the list are explored. This enables searching over any sequence</span>
<span class="sd">            of parameter settings.</span>

<span class="sd">        scoring : string, callable or None, default=None</span>
<span class="sd">            A string (see model evaluation documentation) or</span>
<span class="sd">            a scorer callable object / function with signature</span>
<span class="sd">            ``scorer(estimator, X, y)``.</span>
<span class="sd">            If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">        fit_params : dict, optional</span>
<span class="sd">            Parameters to pass to the fit method.</span>

<span class="sd">        n_jobs : int, default=1</span>
<span class="sd">            Number of jobs to run in parallel.</span>

<span class="sd">        pre_dispatch : int, or string, optional</span>
<span class="sd">            Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">            execution. Reducing this number can be useful to avoid an</span>
<span class="sd">            explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">            than CPUs can process. This parameter can be:</span>
<span class="sd">                - None, in which case all the jobs are immediately</span>
<span class="sd">                  created and spawned. Use this for lightweight and</span>
<span class="sd">                  fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">                  spawning of the jobs</span>
<span class="sd">                - An int, giving the exact number of total jobs that are</span>
<span class="sd">                  spawned</span>
<span class="sd">                - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">                  as in &#39;2*n_jobs&#39;</span>

<span class="sd">        iid : boolean, default=True</span>
<span class="sd">            If True, the data is assumed to be identically distributed across</span>
<span class="sd">            the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">            and not the mean loss across the folds.</span>

<span class="sd">        cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">            Determines the cross-validation splitting strategy.</span>
<span class="sd">            Possible inputs for cv are:</span>
<span class="sd">            - None, to use the default 3-fold cross-validation,</span>
<span class="sd">            - integer, to specify the number of folds.</span>
<span class="sd">            - An object to be used as a cross-validation generator.</span>
<span class="sd">            - An iterable yielding train/test splits.</span>
<span class="sd">            For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">            either binary or multiclass, `sklearn.model_selection.StratifiedKFold` is used. </span>
<span class="sd">            In all other cases, `sklearn.model_selection.KFold` is used.</span>

<span class="sd">        refit : boolean, default=True</span>
<span class="sd">            Refit the best estimator with the entire dataset.</span>
<span class="sd">            If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">            this GridSearchCV instance after fitting.</span>

<span class="sd">        verbose : integer</span>
<span class="sd">            Controls the verbosity: the higher, the more messages.</span>

<span class="sd">        error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">            Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">            If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">            FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">            step, which will always raise the error.</span>


<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>

<span class="sd">        grid_scores_ : list of named tuples</span>
<span class="sd">            Contains scores for all parameter combinations in param_grid.</span>
<span class="sd">            Each entry corresponds to one parameter setting.</span>
<span class="sd">            Each named tuple has the attributes:</span>
<span class="sd">                * ``parameters``, a dict of parameter settings</span>
<span class="sd">                * ``mean_validation_score``, the mean score over the</span>
<span class="sd">                  cross-validation folds</span>
<span class="sd">                * ``cv_validation_scores``, the list of scores for each fold</span>

<span class="sd">        best_estimator_ : estimator</span>
<span class="sd">            Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">            which gave highest score (or smallest loss if specified)</span>
<span class="sd">            on the left out data. Not available if refit=False.</span>

<span class="sd">        best_score_ : float</span>
<span class="sd">            Score of best_estimator on the left out data.</span>

<span class="sd">        best_params_ : dict</span>
<span class="sd">            Parameter setting that gave the best results on the hold out data.</span>

<span class="sd">        scorer_ : function</span>
<span class="sd">            Scorer function used on the held out data to choose the best</span>
<span class="sd">            parameters for the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>


<div class="viewcode-block" id="RandomizedSearchCV"><a class="viewcode-back" href="../../rsts/codebase/skutil_model_selection.html#skutil.grid_search.RandomizedSearchCV">[docs]</a>    <span class="k">class</span> <span class="nc">RandomizedSearchCV</span><span class="p">(</span><span class="n">fixes</span><span class="o">.</span><span class="n">_SK17RandomizedSearchCV</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Randomized search on hyper parameters. This class is a skutil fix of the sklearn </span>
<span class="sd">        0.17 RandomizedSearchCV module, and allows use with SelectiveMixins and other skutil </span>
<span class="sd">        classes that don&#39;t interact so kindly with other sklearn 0.17 structures.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>

<span class="sd">        estimator : estimator object.</span>
<span class="sd">            A object of that type is instantiated for each grid point.</span>
<span class="sd">            This is assumed to implement the scikit-learn estimator interface.</span>
<span class="sd">            Either estimator needs to provide a ``score`` function,</span>
<span class="sd">            or ``scoring`` must be passed.</span>

<span class="sd">        param_distributions : dict</span>
<span class="sd">            Dictionary with parameters names (string) as keys and distributions</span>
<span class="sd">            or lists of parameters to try. Distributions must provide a ``rvs``</span>
<span class="sd">            method for sampling (such as those from scipy.stats.distributions).</span>
<span class="sd">            If a list is given, it is sampled uniformly.</span>

<span class="sd">        n_iter : int, default=10</span>
<span class="sd">            Number of parameter settings that are sampled. n_iter trades</span>
<span class="sd">            off runtime vs quality of the solution.</span>

<span class="sd">        scoring : string, callable or None, default=None</span>
<span class="sd">            A string (see model evaluation documentation) or</span>
<span class="sd">            a scorer callable object / function with signature</span>
<span class="sd">            ``scorer(estimator, X, y)``.</span>
<span class="sd">            If ``None``, the ``score`` method of the estimator is used.</span>

<span class="sd">        fit_params : dict, optional</span>
<span class="sd">            Parameters to pass to the fit method.</span>

<span class="sd">        n_jobs : int, default=1</span>
<span class="sd">            Number of jobs to run in parallel.</span>

<span class="sd">        pre_dispatch : int, or string, optional</span>
<span class="sd">            Controls the number of jobs that get dispatched during parallel</span>
<span class="sd">            execution. Reducing this number can be useful to avoid an</span>
<span class="sd">            explosion of memory consumption when more jobs get dispatched</span>
<span class="sd">            than CPUs can process. This parameter can be:</span>
<span class="sd">                - None, in which case all the jobs are immediately</span>
<span class="sd">                  created and spawned. Use this for lightweight and</span>
<span class="sd">                  fast-running jobs, to avoid delays due to on-demand</span>
<span class="sd">                  spawning of the jobs</span>
<span class="sd">                - An int, giving the exact number of total jobs that are</span>
<span class="sd">                  spawned</span>
<span class="sd">                - A string, giving an expression as a function of n_jobs,</span>
<span class="sd">                  as in &#39;2*n_jobs&#39;</span>

<span class="sd">        iid : boolean, default=True</span>
<span class="sd">            If True, the data is assumed to be identically distributed across</span>
<span class="sd">            the folds, and the loss minimized is the total loss per sample,</span>
<span class="sd">            and not the mean loss across the folds.</span>

<span class="sd">        cv : int, cross-validation generator or an iterable, optional</span>
<span class="sd">            Determines the cross-validation splitting strategy.</span>
<span class="sd">            Possible inputs for cv are:</span>
<span class="sd">            - None, to use the default 3-fold cross-validation,</span>
<span class="sd">            - integer, to specify the number of folds.</span>
<span class="sd">            - An object to be used as a cross-validation generator.</span>
<span class="sd">            - An iterable yielding train/test splits.</span>
<span class="sd">            For integer/None inputs, if the estimator is a classifier and ``y`` is</span>
<span class="sd">            either binary or multiclass, `sklearn.model_selection.StratifiedKFold` is used. </span>
<span class="sd">            In all other cases, `sklearn.model_selection.KFold` is used.</span>

<span class="sd">        refit : boolean, default=True</span>
<span class="sd">            Refit the best estimator with the entire dataset.</span>
<span class="sd">            If &quot;False&quot;, it is impossible to make predictions using</span>
<span class="sd">            this RandomizedSearchCV instance after fitting.</span>

<span class="sd">        verbose : integer</span>
<span class="sd">            Controls the verbosity: the higher, the more messages.</span>

<span class="sd">        random_state : int or RandomState</span>
<span class="sd">            Pseudo random number generator state used for random uniform sampling</span>
<span class="sd">            from lists of possible values instead of scipy.stats distributions.</span>

<span class="sd">        error_score : &#39;raise&#39; (default) or numeric</span>
<span class="sd">            Value to assign to the score if an error occurs in estimator fitting.</span>
<span class="sd">            If set to &#39;raise&#39;, the error is raised. If a numeric value is given,</span>
<span class="sd">            FitFailedWarning is raised. This parameter does not affect the refit</span>
<span class="sd">            step, which will always raise the error.</span>


<span class="sd">        Attributes</span>
<span class="sd">        ----------</span>

<span class="sd">        grid_scores_ : list of named tuples</span>
<span class="sd">            Contains scores for all parameter combinations in param_grid.</span>
<span class="sd">            Each entry corresponds to one parameter setting.</span>
<span class="sd">            Each named tuple has the attributes:</span>
<span class="sd">                * ``parameters``, a dict of parameter settings</span>
<span class="sd">                * ``mean_validation_score``, the mean score over the</span>
<span class="sd">                  cross-validation folds</span>
<span class="sd">                * ``cv_validation_scores``, the list of scores for each fold</span>

<span class="sd">        best_estimator_ : estimator</span>
<span class="sd">            Estimator that was chosen by the search, i.e. estimator</span>
<span class="sd">            which gave highest score (or smallest loss if specified)</span>
<span class="sd">            on the left out data. Not available if refit=False.</span>

<span class="sd">        best_score_ : float</span>
<span class="sd">            Score of best_estimator on the left out data.</span>

<span class="sd">        best_params_ : dict</span>
<span class="sd">            Parameter setting that gave the best results on the hold out data.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
</pre></div>

           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Taylor Smith, Charles Drotar.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.1.5',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>